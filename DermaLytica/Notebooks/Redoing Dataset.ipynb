{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-25T03:39:56.370377Z",
     "start_time": "2025-02-25T03:39:52.773636Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:41:20.299404Z",
     "start_time": "2025-02-25T03:41:18.746157Z"
    }
   },
   "cell_type": "code",
   "source": "all_data_encoded = pd.read_csv(r\"E:\\Capstone Skin Cancer Project\\Datasets\\all_data_with_paths.csv\")\n",
   "id": "c9f13b0e48d28937",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:41:20.487440Z",
     "start_time": "2025-02-25T03:41:20.319458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "female_label_0 = all_data_encoded[(all_data_encoded['Gender_female'] == 1) & (all_data_encoded['label'] == 0)].sample(5500, random_state=58)\n",
    "male_label_0 = all_data_encoded[(all_data_encoded['Gender_male'] == 1) & (all_data_encoded['label'] == 0)].sample(5500, random_state=58)\n",
    "female_label_1 = all_data_encoded[(all_data_encoded['Gender_female'] == 1) & (all_data_encoded['label'] == 1)].sample(5500, random_state=58)\n",
    "male_label_1 = all_data_encoded[(all_data_encoded['Gender_male'] == 1) & (all_data_encoded['label'] == 1)].sample(5500, random_state=58)\n",
    "\n",
    "filtered_data = pd.concat([female_label_0, male_label_0, female_label_1, male_label_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "all_data_encoded = filtered_data"
   ],
   "id": "5c03d3e74b03724",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:41:37.459188Z",
     "start_time": "2025-02-25T03:41:37.453188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_mask_otsu(image):\n",
    "\t\"\"\"\n",
    "\tCreate an enhanced binary mask using an improved preprocessing pipeline:\n",
    "\t1. Convert to grayscale.\n",
    "\t2. Enhance contrast using CLAHE.\n",
    "\t3. Denoise with a bilateral filter.\n",
    "\t4. Sharpen using an unsharp mask filter.\n",
    "\t5. Optionally smooth with a Gaussian blur.\n",
    "\t6. Apply Otsu's thresholding.\n",
    "\t7. Clean up with morphological operations.\n",
    "\t\"\"\"\n",
    "\t# Convert image to grayscale\n",
    "\t# Convert image to grayscale\n",
    "\tgray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\t# Enhance local contrast using CLAHE\n",
    "\tclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\tenhanced = clahe.apply(gray)\n",
    "\n",
    "\t# Use a bilateral filter to reduce noise while preserving edges\n",
    "\tdenoised = cv2.bilateralFilter(enhanced, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "\t# Sharpen the image using an unsharp masking kernel\n",
    "\tsharpening_kernel = np.array([[-1, -1, -1],\n",
    "\t                              [-1, 9, -1],\n",
    "\t                              [-1, -1, -1]])\n",
    "\tsharpened = cv2.filter2D(denoised, -1, sharpening_kernel)\n",
    "\n",
    "\t# Optional: Apply Gaussian Blur to reduce any high-frequency artifacts\n",
    "\tblurred = cv2.GaussianBlur(sharpened, (5, 5), 0)\n",
    "\n",
    "\t# Apply Otsu's thresholding to create the binary mask\n",
    "\t_, mask = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "\t# Use morphological opening to remove small noise artifacts from the mask\n",
    "\tkernel_morph = np.ones((3, 3), np.uint8)\n",
    "\tmask_clean = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_morph, iterations=1)\n",
    "\n",
    "\treturn mask_clean"
   ],
   "id": "e1499cba51bb6661",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:41:37.498375Z",
     "start_time": "2025-02-25T03:41:37.490176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_image_and_mask(image_path):\n",
    "\t\"\"\"Preprocess an image and create its segmentation mask.\"\"\"\n",
    "\t# Read and preprocess image\n",
    "\timage = cv2.imread(str(image_path))\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t# Create mask\n",
    "\ttry:\n",
    "\t\tmask = create_mask_otsu(image)\n",
    "\t\tmask = (mask > 0).astype(np.uint8)  # Convert to binary 0/1\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Warning: Mask creation failed for {image_path}. Using fallback mask.\")\n",
    "\t\tmask = np.ones(image.shape[:2], dtype=np.uint8)  # Fallback: use entire image\n",
    "\n",
    "\t# Resize both image and mask to 224x224\n",
    "\timage = cv2.resize(image, (224, 224))\n",
    "\tmask = cv2.resize(mask, (224, 224), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\t# Normalize image to [0,1]\n",
    "\timage = image.astype(np.float32) / 255.0\n",
    "\n",
    "\treturn image, mask"
   ],
   "id": "dc84e6acad731d36",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:41:37.556026Z",
     "start_time": "2025-02-25T03:41:37.550531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _bytes_feature(value):\n",
    "\t\"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "\treturn tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_list_feature(value):\n",
    "\t\"\"\"Returns a float_list from a numpy array.\"\"\"\n",
    "\treturn tf.train.Feature(float_list=tf.train.FloatList(value=value.flatten()))"
   ],
   "id": "8cbe3ebf63d84965",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:41:37.605264Z",
     "start_time": "2025-02-25T03:41:37.600017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def serialize_example(image, mask, metadata, label):\n",
    "\t\"\"\"\n",
    "\tCreates a tf.Example message ready to be written to a file.\n",
    "\t\"\"\"\n",
    "\t# Convert image to bytes\n",
    "\timage_bytes = tf.io.encode_jpeg(tf.cast(image * 255, tf.uint8)).numpy()\n",
    "\n",
    "\t# Convert mask to bytes - ensure mask is 3D\n",
    "\tmask_3d = np.expand_dims(mask, axis=-1)  # Add channel dimension\n",
    "\tmask_bytes = tf.io.encode_jpeg(tf.cast(mask_3d * 255, tf.uint8)).numpy()\n",
    "\n",
    "\tfeature = {\n",
    "\t\t\t'image':    _bytes_feature(image_bytes),\n",
    "\t\t\t'mask':     _bytes_feature(mask_bytes),\n",
    "\t\t\t'metadata': tf.train.Feature(float_list=tf.train.FloatList(value=metadata)),\n",
    "\t\t\t'label':    tf.train.Feature(float_list=tf.train.FloatList(value=[label]))\n",
    "\t}\n",
    "\n",
    "\treturn tf.train.Example(features=tf.train.Features(feature=feature))"
   ],
   "id": "742211c19dddb3a5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:41:37.620788Z",
     "start_time": "2025-02-25T03:41:37.615787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def write_tfrecord(data, filename):\n",
    "\t\"\"\"Write dataset to TFRecord including segmentation masks.\"\"\"\n",
    "\twith tf.io.TFRecordWriter(filename) as writer:\n",
    "\t\tfor idx, row in data.iterrows():\n",
    "\t\t\ttry:\n",
    "\t\t\t\t# Process image and create mask\n",
    "\t\t\t\timage, mask = preprocess_image_and_mask(row['image_path'])\n",
    "\n",
    "\t\t\t\t# Get metadata and label\n",
    "\t\t\t\tmetadata_cols = [col for col in data.columns if col not in ['isic_id', 'image_path', 'label']]\n",
    "\t\t\t\tmetadata = row[metadata_cols].values.astype(np.float32)\n",
    "\t\t\t\tlabel = row['label']\n",
    "\n",
    "\t\t\t\t# Create and write TF Example\n",
    "\t\t\t\ttf_example = serialize_example(image, mask, metadata, label)\n",
    "\t\t\t\twriter.write(tf_example.SerializeToString())\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(f\"Error processing image {row['image_path']}: {str(e)}\")\n",
    "\t\t\t\tcontinue"
   ],
   "id": "f539b864dec6bc5a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:41:37.733031Z",
     "start_time": "2025-02-25T03:41:37.649031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset\n",
    "train_data, test_data = train_test_split(all_data_encoded, test_size=0.2, random_state=42, shuffle=True)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.3, random_state=24, shuffle=True)\n",
    "\n",
    "print(f\"✅ Train samples: {len(train_data)}\")\n",
    "print(f\"✅ Test samples: {len(test_data)}\")\n",
    "print(f\"✅ Validation samples: {len(val_data)}\")"
   ],
   "id": "84f692dd4e91633c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train samples: 12320\n",
      "✅ Test samples: 4400\n",
      "✅ Validation samples: 5280\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:49:47.164425Z",
     "start_time": "2025-02-25T03:41:37.775275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "write_tfrecord(train_data, r\"E:\\Capstone Skin Cancer Project\\Datasets\\train.tfrecord\")\n",
    "write_tfrecord(val_data, r\"E:\\Capstone Skin Cancer Project\\Datasets\\validation.tfrecord\")\n",
    "write_tfrecord(test_data, r\"E:\\Capstone Skin Cancer Project\\Datasets\\test.tfrecord\")\n",
    "\n",
    "print(\"✅ TFRecord creation complete!\")"
   ],
   "id": "7679351bb2c91cad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TFRecord creation complete!\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
